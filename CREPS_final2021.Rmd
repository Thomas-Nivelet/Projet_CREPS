---
title: "Projet CREPS"
output:
  pdf_document:
    fig_height: 4
    fig_width: 5.5
    number_sections: yes
    toc: yes
date: "`r Sys.Date()`"
subtitle: "Mise en place d'un modèle statistique pour validaton du testing TM2S"
geometry: "left=3cm,right=3cm,top=3cm,bottom=3cm"
header-includes:
- \usepackage{authblk}
- \usepackage[french]{babel}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \renewcommand\headrulewidth{1pt}
- \fancyhead[L]{\scshape \leftmark}
- \fancyhead[R]{\bfseries Projet tutoré}
- \fancyfoot[L]{INSA Toulouse}
- \author{\bfseries Célia DULUC, Thomas NIVELET, Alexia GHOZLAND}
- \affil{4\textsuperscript{e} année MA}
- \affil{INSA Toulouse}
- \affil{\small Année universitaire 2020-2021}
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
```

**Importation des librairies `R` nécessaires**

```{r, include=FALSE}
library(readxl)
library(ggplot2)
library(ggmosaic)
library(MASS)
library(dplyr)
library(fmsb)
library(corrplot)
```

**Importation des données**

```{r}
# Importation du fichier de données depuis un .xlsx
donnees_creps21 <- read_excel("donnees_finales_2021.xlsx")
```

# Statistiques descriptives : première prise en main des données

## Statistiques unidimensionnelles : étude générale des pôles et des scores obtenus

```{r}
# Redéfinition de la variable qualitative à bon escient (en facteurs)
donnees_creps21$POLES <- as.factor(donnees_creps21$POLES)

# Vérification du contenu et présentation sommaire des variables
summary(donnees_creps21)
head(donnees_creps21)
```

```{r}

pie(table(donnees_creps21$POLES), col = c("lightskyblue2", "lightgoldenrod3", "mistyrose4", "lightcoral", "mediumblue", "lightseagreen", "darkorange2", "brown4"),main = "Répartition des athlètes dans les pôles")

barplot(table(factor(donnees_creps21$SCORE, levels = 0:20)), main = "Scores obtenus - Tous pôles confondus", ylim = c(0,20), cex.names = 0.6, ylab = "Effectifs", xlab= "Score", col = heat.colors(20))

dim(donnees_creps21)
```

Données concernant les athlètes du CREPS de la saison 2020-2021 qui ont pu passer le TM2S, soit 86 athlètes.

```{r}
SCORE <- donnees_creps21$SCORE
POLES <- donnees_creps21$POLES

tab_mean <- tapply(SCORE, POLES, mean) # Moyenne des scores pour chaque pôle
tab_median <- tapply(SCORE, POLES, median) # Médiane des scores pour chaque pôle
tab_mean
tab_median
```

```{r}
boxplot(donnees_creps21$SCORE ~ donnees_creps21$POLES, cex.axis = 0.8, main = "Boxplots parallèles des scores en fonction des pôles", xlab = "Pôles", ylab = "Score")
```

```{r}
par(mfrow=c(1,2))
plot(donnees_creps21$SCORE_MOB ~donnees_creps21$POLES, ylab="Score en mobilité", xlab="Poles")
plot(donnees_creps21$SCORE_STAB ~donnees_creps21$POLES, ylab="Score en stabilité", xlab="Poles")
```

```{r}
#essai
coord_x=donnees_creps21$SCORE
coord_y=donnees_creps21$BLESS
reg <- lm(coord_y ~ coord_x)
nom=donnees_creps21$INDIV #ou rien mettre et ça donne des numéros de 1 à 86 (plus propre) mais du coup on sait pas quel pôle...
plot(coord_x,coord_y,  ylab="Number of injuries", xlab="Score", main="Number of injuries VS score", cex.main=0.7)
abline(reg, col = "red")
#text(coord_x,coord_y,nom, pos=2, offset=0.5, cex=0.7)
summary(reg)
```

On réalise un test de Fisher de sous-modèle : modèle blanc (simplement ajusté par une constante contre le modèle de régression linéaire).
La p-valeur est largement supérieure à un seuil de 0.05%.
On ne peut donc pas rejeter le modèle blanc.
Autrement dit, le modèle de régression linéaire n'ajuste pas les données.
On ne peut pas conclure que le score au TM2S explique le nombre de blessures qu'un athlète se fait au cours d'une saison.

```{r}
#essai
coord_x=donnees_creps21$SCORE
coord_y_1=donnees_creps21$INDISPO_1
reg1 <- lm(coord_y_1 ~ coord_x)
nom=donnees_creps21$INDIV #ou rien mettre et ça donne des numéros de 1 à 86 (plus propre) mais du coup on sait pas quel pôle...
plot(coord_x,coord_y_1,  ylab="Number of injuries of type 1", xlab="Score", main="Number of injuries of type 1 VS score", cex.main=1.1)
abline(reg1, col = "red")
#text(coord_x,coord_y,nom, pos=2, offset=0.5, cex=0.7)
summary(reg1)
```

```{r}
#essai
coord_x=donnees_creps21$SCORE
coord_y_2=donnees_creps21$INDISPO_2
reg2 <- lm(coord_y_2 ~ coord_x)
nom=donnees_creps21$INDIV #ou rien mettre et ça donne des numéros de 1 à 86 (plus propre) mais du coup on sait pas quel pôle...
plot(coord_x,coord_y_2,  ylab="Number of injuries of type 2", xlab="Score", main="Number of injuries of type 2 VS score", cex.main=1)
abline(reg2, col = "red")
#text(coord_x,coord_y,nom, pos=2, offset=0.5, cex=0.7)
summary(reg2)
```

```{r}
#essai
coord_x=donnees_creps21$SCORE
coord_y_3=donnees_creps21$INDISPO_3
reg3 <- lm(coord_y_3 ~ coord_x)
nom=donnees_creps21$INDIV #ou rien mettre et ça donne des numéros de 1 à 86 (plus propre) mais du coup on sait pas quel pôle...
plot(coord_x,coord_y_3,  ylab="Number of injuries of type 3", xlab="Score", main="Number of injuries of type 3 VS score", cex.main=0.7)
abline(reg3, col = "red")
#text(coord_x,coord_y,nom, pos=2, offset=0.5, cex=0.7)
summary(reg3)
```

Au vu des résultats ci-dessus, les scores au TM2S ne semblent pas non plus liés à la fréquence d'un type de blessures en particulier.

Réflexion: Pourquoi ces résultats (non significatifs) ?
- Trop de blessures sont liés à des chocs, des contacts, des situations communes (pas de sport mais chute à vélo par exemple?) ?
Donc au final, le score au test ne peut pas influer sur l'occurence de blessures.
Ce serait top de pouvoir distinguer même si c'est réellement presque impossible.
- saison peu représentative avec le Covid???
Pas de réelles compétitions?
- un temps total d'arrêt en semaine aurait été plus représentatif que le nombre de blessures?
Car une blessure n'a pas forcément le même poids.
Même si la distinction en 3 types de blessures est fournie, il est difficile d'aggréger les résultats.
- ???

ESSAYER régression linéaire multiple!
Expliquer le score en fonction de trois variables INDISPO_i (i=1,2,3) pour voir si un lien apparaît.
(même si c'est un peu "à l'envers").

```{r}
#essai
coord_y_Score=donnees_creps21$SCORE
coord_x_1=donnees_creps21$INDISPO_1
coord_x_2=donnees_creps21$INDISPO_2
coord_x_3=donnees_creps21$INDISPO_3
reg4 <- lm(coord_y_Score ~ coord_x_1 + coord_x_2 + coord_x_3) #modèle additif
summary(reg4)
```

OK bon beh mauvaise idée -\> modèle tout pourri (p-valeur énorme).

### Ajustement modèle log-linéaire (comptage des blessures)

Un autre moyen, peut être plus adapté dans notre contexte, serait d'ajuster un modèle de régression loglinéaire (ou régression de Poisson), pour compter le nombre de blessures en fonction du score obtenu au TM2s.
On est dans le cadre d'un modèle linéaire généralisé, ce qui serait peut être plus adapté, vu que notre variable réponse (le nombre de blessures) est en réalité discrète, elle apparaît comme une variable de comptage.

-   Rappeler l'écriture du modèle ? Fonction de lien ?

```{r}
modpois = glm(BLESS ~  SCORE, data = donnees_creps21, family = poisson)
summary(modpois)
```

```{r}
plot(modpois)
```

Le modèle blanc est donné par la commande suivante :

```{r}
whitemod <- glm(coord_y ~  1, data = donnees_creps21, family = poisson)
```

On effectue un test de sous-modèle (c'est ici un test de rapport de vraisemblance) :

```{r}
anova(whitemod,modpois, test="Chisq")
```

Le test de rapport de vraisemblance nous donne une $p$-valeur de 0.1045, donc supérieure au seuil de 0.05.
On ne peut donc pas rejeter le modèle blanc.
Autrement dit, le modèle de régression loglinéaire simple n'ajuste pas les données.
On ne peut pas conclure que le score au TM2S explique le nombre de blessures qu'un athlète connaît au cours d'une saison, et ce, même si la \$p\$-valeur est plus faible qu'avec le modèle de régression linéaire.
Le comptage via un modèle de régression loglinéaire serait donc plus adapté qu'un modèle de régression linéaire simple ??

Toutefois, si l'on se place à un risque de $10\%$, on se trouve dans une zone grise, donc ce modèle n'apparaît pas complètement hors sujet... Nous faudrait-il peut être davantage de données ?
Baseball et Rugby ?
Regarder spécifiquement les types d'indispo ?

Inconvénient/Limite : Les scores sont des valeurs "discrètes" ????
Dispose-t-on d'assez de valeurs ???
Il faudrait pouvoir différencier les blessures avec donc d'autres variables : qualitatives, pour une ANOVA?
Blessures sont parfois des chocs, des coups, des blessures minimes, et d'autres sont musculaires, touchent les ligaments, donc l'indispo est bien plus longue... Trop simpliste de tout mélanger ?

Faire la même chose, en précisant avec les scores en stabilité et en mobilité ?
Types de blessures à discriminer ??

-   Reprenons notre étude sur le modèle log-linéaire, et ajustons le modèle complet.
    Par le biais de ce modèle, on cherche à expliquer le nombre de blessures par le score total obtenu au TM2S, ainsi que le pôle auquel appartient l'athlète, avec des interactions entre ces deux variables explicatives.

```{r}
modpoiscomplet <- glm(BLESS ~  SCORE*POLES, data = donnees_creps21, family = poisson)
summary(modpoiscomplet)
```

Au vu des résultats, pas beaucoup de paramètres associés aux variables semblent très significatifs... Commençons par voir si l'on peut annuler les interactions présentes dans le modèle complet, par un test de sous-modèle de rapport de vraisemblance :

```{r}
# On ajuste le modèle additif (sans interactions):
modpoisadd <- glm(BLESS ~  SCORE+POLES, data = donnees_creps21, family = poisson)
summary(modpoisadd)
```

Test de sous-modèle de rapport de vraisemblance :

```{r}
anova(modpoisadd,modpoiscomplet,test="Chisq")
```

D'après la sortie précédente, on obtient une $p$-valeur supérieure à $5\%$ (proche même de $20\%$), on ne rejette donc pas l'hypothèse nulle.
On peut simplifier le modèle en annulant les interactions.

En cascade, voyons si l'on peut annuler l'effet des pôles... La commande suivante nous permet d'ajuster un modèle log-linéaire pour expliquer le nombre de blessures en fonction uniquement du score général au TM2S

```{r}
modpoisscore <- glm(BLESS ~  SCORE, data = donnees_creps21, family = poisson)
summary(modpoisscore)
```

Test de sous-modèle :

```{r}
anova(modpoisscore,modpoisadd,test="Chisq")
```

On obtient une $p$-valeur très inférieure à $5\%$ , on ne peut donc *a priori* pas simplifier le modèle, il y a bien un effet de l'appartenance au pôle sur les blessures que connaissent les athlètes.
Toutefois, on a pu remarquer que certains pôles influaient de manière plus significative que le score au TM2S (cf. les \$p\$- valeurs des tests de nullité des paramètres dans les sorties), ce qui explique pourquoi l'on ne peut pas simplifier le modèle ici.
Ainsi, le modèle ne permet pas non plus de bien ajuster les données ici.

Et si l'on restreignait notre étude aux indisponibilités de type 3...

```{r}
modpoiscomplet3 <- glm(INDISPO_3 ~  SCORE*POLES, data = donnees_creps21, family = poisson)
summary(modpoiscomplet3)
```

```{r}
modpoisadd3 <- glm(INDISPO_3 ~  SCORE+POLES, data = donnees_creps21, family = poisson)
summary(modpoisadd3)
```

```{r}
anova(modpoisadd3,modpoiscomplet3,test="Chisq")
```

Avec certitude, on peut à nouveau annuler les interactions...

```{r}
modpoisscore3 <- glm(INDISPO_3 ~  SCORE, data = donnees_creps21, family = poisson)
summary(modpoisscore3)
```

```{r}
anova(modpoisscore3,modpoisadd3, test="Chisq")
```

On peut cette fois simplifier le modèle, il n'y a visiblement pas d'effet "appartenance au pôle sportif" sur le nombre de blessures.
Comparons ce modèle au modèle blanc.

```{r}
anova(glm(INDISPO_3 ~ 1, data = donnees_creps21, family = poisson),modpoisscore3, test="Chisq")
```

On obtient une $p$-valeur de 0.3, ce modèle ne semble pas performance pour expliquer les indisponibilités de type 3.

Etude sur les maintiens:

```{r}
# Importation du fichier de données depuis un .xlsx
donnees_maintiens21 <- read_excel("CREPS_Maintien.xlsx")
```

Pour comparer le nombre de blessures avant la mise en place des routines correctives (épidémiologie 2019-2020) avec le nombre de blessures après la mise en place de celles-ci (épidémiologie 2020-2021) : Il suffit d'effectuer un t-test « pairé ».
On fait ce test « pairé » car on dispose de deux mesures sur un même échantillon (on parle donc d'échantillons dépendants).
On va en fait comparer les moyennes sur ces deux sets de mesures.
On émet l'hypothèse qu'elles sont égales (i.e. il n'y a pas eu d'effet des routines correctives), et on la compare à l'hypothèse que la moyenne de blessures après routine corrective est inférieure à la moyenne avant l'application de la routine de travail (i.e. la routine corrective a porté ses fruits).

On veut comparer l'hypothèse selon laquelle la différence significative (donc la moyenne des deux échantillons est égale), à celle selon laquelle la différence est significative (donc dans notre cas la moyenne de blessures avant le test est supérieure à la moyenne de blessures après le test).

```{r}
# Test de student apparié 
comp_bless <- t.test(donnees_maintiens21$NB_BLESS_19, donnees_maintiens21$NB_BLESS_21, paired=TRUE, alternative="greater")
comp_bless$p.value # Affichage de la p-value

#alternative="greater" is the alternative that x has a larger mean than y. 
```

La p-valeur est grande.
Il n'y a donc pas de différence significative.
On ne peut pas dire que les routines correctives ont permis de diminuer significativement le nombre de blessures.

On peut tout de même s'assurer que l'on ne constate pas une tendance inverse (i.e. la différence a été dans le sens inverse à celui voulu : plus de blessures après la mise en place des routines correctives).

```{r}
# Test de student apparié 
comp_bless_inv <- t.test(donnees_maintiens21$NB_BLESS_21, donnees_maintiens21$NB_BLESS_19, paired=TRUE, alternative="greater")
comp_bless_inv$p.value # Affichage de la p-value
```

La p-valeur est encore une fois très grande (quoique plus faible qu'avant?!).
Il n'y a donc pas eu d'effet inverse non plus!

Les routines correctives n'ont pas permis d'influer sur le nombre de blessures de chaque athlète.

On peut essayer avec seulement les blessures de niveau 3 (car ce sont elles que l'on cherche à réduire en priorité):

```{r}
# Test de student apparié 
comp_bless_seuil3 <- t.test(donnees_maintiens21$INDISPO_3_19, donnees_maintiens21$INDISPO_3_21, paired=TRUE, alternative="greater")
comp_bless_seuil3$p.value # Affichage de la p-value
```

La p-valeur ne nous donne pas de résultats significatifs.
Mais on peut cependant noter qu'elle nous donne de biens meilleurs résultats que dans le cas général du nombre de blessures!

```{r}
#Pour apprécier le nombre de blessures de seuil 3 sur chacune des années
tot_ind_3_21=0
for (i in donnees_maintiens21$INDISPO_3_21){
  tot_ind_3_21 = tot_ind_3_21 + i
}
tot_ind_3_21

tot_ind_3_19=0
for (i in donnees_maintiens21$INDISPO_3_19){
  tot_ind_3_19 = tot_ind_3_19 + i
}
tot_ind_3_19
```

Par curiosité, voyons ce que cela peut donner sur les blessures de seuil 1 et 2.

```{r}
# Test de student apparié 
comp_bless_seuil1 <- t.test(donnees_maintiens21$INDISPO_1_19, donnees_maintiens21$INDISPO_1_21, paired=TRUE, alternative="greater")
comp_bless_seuil1$p.value # Affichage de la p-value
```

Les résultats semblent catastrophiques ici!

```{r}
#Pour apprécier le nombre de blessures de seuil 3 sur chacune des années
tot_ind_1_21=0
for (i in donnees_maintiens21$INDISPO_1_21){
  tot_ind_1_21 = tot_ind_1_21 + i
}
tot_ind_1_21

tot_ind_1_19=0
for (i in donnees_maintiens21$INDISPO_1_19){
  tot_ind_1_19 = tot_ind_1_19 + i
}
tot_ind_1_19
```

En effet, il y a plus de blessures de seuil 1 sur la saison 2020-2021 que sur la saison 2019-2020!

```{r}
# Test de student apparié 
comp_bless_seuil2 <- t.test(donnees_maintiens21$INDISPO_2_19, donnees_maintiens21$INDISPO_2_21, paired=TRUE, alternative="greater")
comp_bless_seuil2$p.value # Affichage de la p-value
```

```{r}
#Pour apprécier le nombre de blessures de seuil 3 sur chacune des années
tot_ind_2_21=0
for (i in donnees_maintiens21$INDISPO_2_21){
  tot_ind_2_21 = tot_ind_2_21 + i
}
tot_ind_2_21

tot_ind_2_19=0
for (i in donnees_maintiens21$INDISPO_2_19){
  tot_ind_2_19 = tot_ind_2_19 + i
}
tot_ind_2_19
```

Remarque: nous avons ici comparer l'évolution des blessures et indisponibilités entre les deux saisons passées.
Cependant, pouvons-nous réellement conclure l'efficacité des routines correctives avec cela?
En effet, une routine corrective est spécifique.
C'est-à-dire que selon le score obtenu au premier test, elle vise certaines parties du corps uniquement.
Les blessures pourraient se trouver à d'autres endroits que ceux corrigés par la routine.
Néanmoins, on rappelle que les routines correctives sont mises en place selon les faiblesses censées être mises en avant.
Si le nombre de blessures n'est pas réduit, peut-être que les routines correctives ne ciblaient pas tous les points faibles d'un athlète?
Et par extension, le test TM2S ne parvenait peut-être pas à mettre en évidence les faiblesses d'un athlète?
Propos à nuancer: il faut un long moment pour corriger des défauts de mobilité/stabilité.
Ainsi, il serait intéressant de comparer le nombre de blessures sur plusieurs saisons!
